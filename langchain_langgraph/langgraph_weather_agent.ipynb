{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# LangGraph Weather Agent\n",
        "\n",
        "Notebook version of the LangGraph weather agent demo. It builds a small tool-calling graph to fetch weather for mentioned cities.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "import time\n",
        "import requests\n",
        "from pathlib import Path\n",
        "from requests.exceptions import RequestException, Timeout\n",
        "from langgraph.graph import MessagesState, StateGraph, START, END\n",
        "from langgraph.prebuilt import ToolNode, tools_condition\n",
        "from langchain_openai import ChatOpenAI\n",
        "from langchain_core.messages import SystemMessage, AIMessage, HumanMessage\n",
        "from dotenv import load_dotenv\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Configuration & constants\n",
        "WEATHER_CODE_MAP = {\n",
        "    0: \"Clear sky\", 1: \"Mainly clear\", 2: \"Partly cloudy\", 3: \"Overcast\",\n",
        "    45: \"Fog\", 61: \"Slight rain\", 63: \"Moderate rain\", 65: \"Heavy rain\",\n",
        "    75: \"Heavy snow\", 95: \"Thunderstorm\", 99: \"Thunderstorm with hail\"\n",
        "}\n",
        "\n",
        "OPEN_METEO_GEOCODE_URL = \"https://geocoding-api.open-meteo.com/v1/search\"\n",
        "OPEN_METEO_FORECAST_URL = \"https://api.open-meteo.com/v1/forecast\"\n",
        "HTTP_TIMEOUT_SECS = 8\n",
        "RETRY_ATTEMPTS = 2\n",
        "RETRY_BACKOFF_SECS = 0.6\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Network resilience logic\n",
        "def _request_with_retries(method: str, url: str, **kwargs) -> requests.Response:\n",
        "    \"\"\"Make an HTTP request with retries and backoff.\"\"\"\n",
        "    last_exc = None\n",
        "    for attempt in range(RETRY_ATTEMPTS + 1):\n",
        "        try:\n",
        "            return requests.request(method, url, timeout=HTTP_TIMEOUT_SECS, **kwargs)\n",
        "        except (RequestException, Timeout) as exc:\n",
        "            last_exc = exc\n",
        "            if attempt < RETRY_ATTEMPTS:\n",
        "                time.sleep(RETRY_BACKOFF_SECS * (attempt + 1))\n",
        "            else:\n",
        "                raise last_exc\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Tools\n",
        "\n",
        "def geocode_city(name: str) -> dict:\n",
        "    \"\"\"Look up latitude/longitude for a city using Open-Meteo.\"\"\"\n",
        "    params = {\"name\": name, \"count\": 1, \"format\": \"json\"}\n",
        "    resp = _request_with_retries(\"GET\", OPEN_METEO_GEOCODE_URL, params=params)\n",
        "    data = resp.json()\n",
        "    results = data.get(\"results\") or []\n",
        "    if not results:\n",
        "        raise ValueError(f\"Could not geocode city '{name}'.\")\n",
        "    r0 = results[0]\n",
        "    res_lat_lon = {\"city\": r0[\"name\"], \"lat\": r0[\"latitude\"], \"lon\": r0[\"longitude\"]}\n",
        "    print(\"res_lat_lon:\\n\", res_lat_lon)\n",
        "    return res_lat_lon\n",
        "\n",
        "\n",
        "def current_weather(lat: float, lon: float) -> dict:\n",
        "    \"\"\"Fetch current weather for coordinates using Open-Meteo.\"\"\"\n",
        "    params = {\n",
        "        \"latitude\": lat,\n",
        "        \"longitude\": lon,\n",
        "        \"current\": [\"temperature_2m\", \"weather_code\", \"wind_speed_10m\"],\n",
        "        \"timezone\": \"auto\",\n",
        "    }\n",
        "    resp = _request_with_retries(\"GET\", OPEN_METEO_FORECAST_URL, params=params)\n",
        "    data = resp.json()\n",
        "    cur = data.get(\"current\")\n",
        "    if not cur:\n",
        "        raise ValueError(\"No weather data returned.\")\n",
        "    return {\n",
        "        \"temperature\": cur[\"temperature_2m\"],\n",
        "        \"weather_code\": cur[\"weather_code\"],\n",
        "        \"windspeed\": cur[\"wind_speed_10m\"],\n",
        "    }\n",
        "\n",
        "\n",
        "def format_weather_summary(city: str, payload: dict) -> str:\n",
        "    \"\"\"Decodes weather codes and returns a human-readable one-liner.\"\"\"\n",
        "    code = payload[\"weather_code\"]\n",
        "    desc = WEATHER_CODE_MAP.get(code, f\"Unknown weather code {code}\")\n",
        "    temp_c = payload[\"temperature\"]\n",
        "    wind = payload[\"windspeed\"]\n",
        "    return f\"{city}: {desc}, {round(temp_c)}°C, wind {round(wind, 1)} m/s\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load .env and init LLM\n",
        "project_dir = Path(__file__).resolve().parent if \"__file__\" in globals() else Path.cwd()\n",
        "load_dotenv(dotenv_path=project_dir / \".env\")\n",
        "openai_api_key = os.getenv(\"OPENAI_API_KEY\")\n",
        "if not openai_api_key:\n",
        "    raise ValueError(\"OPENAI_API_KEY not set in environment or .env file.\")\n",
        "\n",
        "llm = ChatOpenAI(model=\"gpt-4o\", api_key=openai_api_key)\n",
        "llm_with_tools = llm.bind_tools([geocode_city, current_weather])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Nodes\n",
        "class MyMessagesState(MessagesState):\n",
        "    pass\n",
        "\n",
        "def tool_calling_llm(state: MyMessagesState):\n",
        "    system = SystemMessage(content=(\n",
        "        \"You are a helpful weather assistant. \"\n",
        "        \"When the user mentions cities, call geocode_city for each city, then call current_weather. \"\n",
        "        \"Prefer Celsius unless the user explicitly requests Fahrenheit/imperial.\"\n",
        "    ))\n",
        "    prompt = [system] + state[\"messages\"]\n",
        "    response = llm_with_tools.invoke(prompt)\n",
        "    return {\"messages\": [response]}\n",
        "\n",
        "\n",
        "def compose_final_answer(state: MyMessagesState):\n",
        "    system = SystemMessage(content=(\n",
        "        \"Summarize any fetched weather results in plain language. \"\n",
        "        \"Output one line per city, with condition, temperature, and wind. \"\n",
        "        \"If any city failed, acknowledge it clearly instead of guessing.\"\n",
        "    ))\n",
        "    response = llm.invoke([system] + state[\"messages\"])\n",
        "    return {\"messages\": [response]}\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Graph construction\n",
        "builder = StateGraph(MyMessagesState)\n",
        "\n",
        "builder.add_node(\"tool_calling_llm\", tool_calling_llm)\n",
        "builder.add_node(\"tools\", ToolNode([geocode_city, current_weather]))\n",
        "builder.add_node(\"compose_final\", compose_final_answer)\n",
        "\n",
        "builder.add_edge(START, \"tool_calling_llm\")\n",
        "builder.add_conditional_edges(\n",
        "    \"tool_calling_llm\",\n",
        "    tools_condition,\n",
        "    {\"tools\": \"tools\", END: \"compose_final\"},\n",
        ")\n",
        "builder.add_edge(\"tools\", \"tool_calling_llm\")  # loop for multiple tool calls\n",
        "builder.add_edge(\"compose_final\", END)\n",
        "\n",
        "graph = builder.compile()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Visualization helper (optional; requires graphviz for PNG)\n",
        "def visualize_graph(graph):\n",
        "    g = graph.get_graph()\n",
        "    print(\"\\n--- Graph (ASCII) ---\")\n",
        "    print(g.draw_ascii())\n",
        "    print(\"\\n--- Graph (Mermaid) ---\")\n",
        "    print(g.draw_mermaid())\n",
        "    try:\n",
        "        png_bytes = g.draw_mermaid_png()\n",
        "        with open(\"langgraph_weather_agent.png\", \"wb\") as f:\n",
        "            f.write(png_bytes)\n",
        "        print(\"\\nSaved PNG to langgraph_weather_agent.png\")\n",
        "    except Exception as exc:\n",
        "        print(f\"\\nPNG not generated (graphviz likely missing): {exc}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "res_lat_lon:\n",
            " {'city': 'London', 'lat': 51.50853, 'lon': -0.12574}\n",
            "res_lat_lon:\n",
            " {'city': 'Paris', 'lat': 48.85341, 'lon': 2.3488}\n",
            "[ASSISTANT] Here's the current weather for Paris and London:\n",
            "\n",
            "- **Paris**: The temperature is 0.6°C with clear skies. The wind speed is 4.7 km/h.\n",
            "\n",
            "- **London**: The temperature is 0.9°C with mainly clear weather. The wind speed is 10.0 km/h.\n",
            "[ASSISTANT] Summarize the email exchange between Jane and Tom in plain language. Jane reached out to Tom last week.\n"
          ]
        }
      ],
      "source": [
        "# Run a test case\n",
        "prompt = \"Weather in Paris and London please.\"\n",
        "result = graph.invoke({\"messages\": [HumanMessage(content=prompt)]})\n",
        "for m in result[\"messages\"]:\n",
        "    if isinstance(m, AIMessage) and not m.tool_calls:\n",
        "        print(f\"[ASSISTANT] {m.content}\")\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "--- Graph (ASCII) ---\n",
            "         +-----------+               \n",
            "         | __start__ |               \n",
            "         +-----------+               \n",
            "                *                    \n",
            "                *                    \n",
            "                *                    \n",
            "      +------------------+           \n",
            "      | tool_calling_llm |           \n",
            "      +------------------+           \n",
            "         ***        ...              \n",
            "        *              .             \n",
            "      **                ..           \n",
            "+-------+         +---------------+  \n",
            "| tools |         | compose_final |  \n",
            "+-------+         +---------------+  \n",
            "                          *          \n",
            "                          *          \n",
            "                          *          \n",
            "                     +---------+     \n",
            "                     | __end__ |     \n",
            "                     +---------+     \n",
            "\n",
            "--- Graph (Mermaid) ---\n",
            "---\n",
            "config:\n",
            "  flowchart:\n",
            "    curve: linear\n",
            "---\n",
            "graph TD;\n",
            "\t__start__([<p>__start__</p>]):::first\n",
            "\ttool_calling_llm(tool_calling_llm)\n",
            "\ttools(tools)\n",
            "\tcompose_final(compose_final)\n",
            "\t__end__([<p>__end__</p>]):::last\n",
            "\t__start__ --> tool_calling_llm;\n",
            "\ttool_calling_llm -. &nbsp;__end__&nbsp; .-> compose_final;\n",
            "\ttool_calling_llm -.-> tools;\n",
            "\ttools --> tool_calling_llm;\n",
            "\tcompose_final --> __end__;\n",
            "\tclassDef default fill:#f2f0ff,line-height:1.2\n",
            "\tclassDef first fill-opacity:0\n",
            "\tclassDef last fill:#bfb6fc\n",
            "\n",
            "\n",
            "Saved PNG to langgraph_weather_agent.png\n"
          ]
        }
      ],
      "source": [
        "# Optionally visualize\n",
        "visualize_graph(graph)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "ml_interview_env_py312",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
